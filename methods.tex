%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
%  QPLIB-2.3.tex
%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

\subsection{Solution Methods and Solvers}\label{sec:algo}

In this section we provide a quick overview of existing solution methods for QP, restricting ourselves to these implemented by the set of solvers considered in this paper (see \S\ref{subsec:solver}). For each approach we briefly describe  the formulation they address according to the classification set out in \S\ref{sec:classification}. We remark that many solvers implement more than one algorithm, which the user can choose at runtime. Moreover, algorithms are typically implemented in different ways within different solvers, so that the same conceptual algorithm can sometimes yield different results or performance measures on the same instances.

  Solution methods for QP can be broadly organized in four categories \cite{neumaier}: \emph{incomplete}, \emph{asymptotically complete}, \emph{complete}, and \emph{rigorous}.
  \begin{itemize}
  \item \textit{Incomplete} methods are only able to identify solutions, often locally optimal according to a suitable notion, and may even fail to find one even when one exists; in particular, they are typically unable to determine that an instance has no solution.
  \item \textit{Asymptotically complete} methods can find a globally optimal solution with probability one in infinite time, but  they cannot prove that a given instance is infeasible \textcolor{green}{(see \S\ref{sss:asymc} below))}.
  \item \textit{Complete} methods find an approximate globally optimal solution within a prescribed optimality tolerance within finite time, or prove that none such exists (but see \S\ref{s:complete} below); they are often referred to as \emph{exact} methods in the computational optimization community.
  \item \textit{Rigorous} methods find globally optimal solutions within given tolerances even in the presence of rounding errors, except for ``near-degenerate cases''. Since none of the solvers we are using can be classified as rigorous, we limit ourselves to declaring solvers complete.
  \end{itemize}

\textcolor{red}{We refer the interested reader to 
\cite{book:2077007} and 
\cite{lee2006quadratic} for further details on the solution methods.}

\input{solvers.tex}

\subsubsection{Incomplete Methods}

Incomplete methods are usually realized as local search algorithms, asymptotically complete methods are usually realized by meta-heuristic methods such as multi-start or simulated annealing, and complete methods for $\mathcal{NP}$-hard problems such as QP are typically realized as implicit exhaustive exploration algorithms. However, these three categories may exhibit some overlap. For example, any deterministic method for solving \textit{QCQ} locally is incomplete in general, but becomes complete for \textit{CCC}, since any local optimum of a convex QP is also global. Therefore, when we state that a given algorithm is incomplete or (asymptotically) complete we mean that it is so the largest problem class that the solver naturally targets, although it may be complete on specific sub-classes. For example, interior point algorithms naturally target NLPs and are incomplete on NLPs, and therefore on \textit{QCQ}, but become complete for \textit{CCC}. In general, all complete methods for a problem class $P$ must be complete for any problem class $Q \subseteq P$, while a complete method for $P$ might be incomplete for a class $R \supset P$.

The solvers in Table \ref{t:solvers} which implement incomplete methods for NLPs (a problem class containing \textit{QCQ}) are \conopt, \ipopt, \minos, \snopt, and \knitro. Note that all these solvers tackle the more general class of NLP, while we use them only for the considerably more restricted class of QP. Aside from solvers provided by GAMS, there are a number of other, specialized, incomplete QP solvers, such as
\cqp \cite{GoulOrbaRobi13:mpc},
\dqp \cite{GoulRobi16:coap} and
\ooqp \cite{GertWrig03:toms}
for convex problems, and
\bqpd \cite{Flet:2000},
\qpa \cite{GoulToin02i} and
\qpb \cite{ConnGoulOrbaToin:2000},
\qpc \cite{GoulOrbaToin03:toms},
\sqic \cite{Gill2015}
for nonconvex ones.

% -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -
\subsubsection{Asymptotically Complete Methods}\label{sss:asymc}

Asymptotically complete methods do not usually require a starting point, and, if given sufficient time (infinite in the worst case) will identify a globally optimal solution with probability one. Most often, these methods are meta-heuristics, involving an element of random choice, which exploit a given (heuristic) local search procedure.

The solvers in Table \ref{t:solvers} which implement asymptotically complete methods are \oqnlp and \knitro (which apply to \textit{QGQ}) as well as \msnlp and certain sub-solvers of \lgo (which apply to \textit{QCQ}).


% -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -
\subsubsection{Complete Methods}\label{s:complete}

Complete methods are often referred to as \emph{exact} in a large part of the mathematical optimization community. This term has to be used with care, as it implicitly makes assumptions on the underlying computational model that may not be acceptable in all cases. For example, the decision version of \textit{QCL} is known to be in the complexity class $\mathcal{NP}$ \cite{vavasis90a}, whereas the same is not known about \textit{LCQ}, even with zero objective. On the other hand, there exists a method for deciding feasibility of systems of polynomial equations and inequalities \cite{tarski-reals}, including the solution of \textit{LCQ} with zero objective function.

To explain this apparent contradiction, we remark that the two statements refer to different computational models: the former is based on the Turing Machine (TM), whereas the latter is based on a computational model that allows operations on real numbers, e.g.~the Real RAM (RRAM) machine \cite{blum}. Due to the potentially infinite nature of exact real arithmetic computations, exact computations on the RRAM necessarily end up being approximate on the TM. Analogously, a complete method may reasonably be called ``exact'' on a RRAM; however, the computers we use in practice are more akin to TMs than RRAMs, and therefore calling \emph{exact} a solver that employs floating point computations is, technically speaking, stretching the meaning of the word. However, because the term is well understood in the computational optimization community, in the following we shall loosen the distinction between complete and exact methods, with either properties intended to mean ``complete'' in the sense of \cite{neumaier}.

Nearly all of the complete solvers in Table \ref{t:solvers} that address $\mathcal{NP}$-hard problems (i.e.~those in \textit{QGQ}$\smallsetminus$\textit{CCC}) are based on Branch-and-Bound (BB) \cite{land_doig}. When the BB algorithm is allowed to branch on coordinate directions corresponding to continuous variables, it is called \emph{spatial} BB (sBB) \cite{dakin,BeLeLiMaWa08}. BB algorithms require exponential time in the worst case, and their exponential behavior unfortunately often shows up in practice. They can also be used heuristically (forsaking their completeness guarantee) in a number of ways, e.g.~by terminating them early. The following solvers from Table \ref{t:solvers} implement complete BB algorithms for \textit{QGQ} or some subclasses: 
%
\begin{itemize}
 \item \antigone, \baron, \couenne, \lindo, and \scip for \textit{QGQ};
 %
 \item \cplex for \textit{QGL} and \textit{CGC};
%
 \item \textcolor{red}{\gurobi and \xpress for \textit{QBC};}
%
 \item \bonmin, \gurobi, \knitro, \mosek, \sbb, and \xpress for \textit{CGC}.
\end{itemize}
%
We remark that \textcolor{red}{the solvers \bonmin, \knitro, and \sbb from} the latter category can be used as incomplete solvers for \textit{QGQ}. We also note that \lgo implements an incomplete BB algorithm for \textit{QCQ} by using bounds obtained from sampling.

Cutting plane approaches construct and iteratively improve a MILP (\textit{LIL}) relaxation of the problem \cite{DuGr86,WePoe02}. The cutting planes for the MILP are generated by linearization (first-order Taylor approximation) of the nonlinearities. If the latter are convex, the MILP provides a valid lower bound for the problem. Additionally, incomplete methods can be used to provide local solutions. Therefore, these methods are complete on \textit{CGC} if a complete method is used to solve the MILP. The latter is typically based on BB, which is therefore a crucial technique also for this class of approaches. Solvers in Table \ref{t:solvers} that implement complete cutting plane methods for \textit{CGC} are \alphaecp, \bonmin (in the algorithmic mode B-OA), and \dicopt.

